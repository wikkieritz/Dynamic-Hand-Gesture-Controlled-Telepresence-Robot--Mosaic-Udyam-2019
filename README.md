# Dynamic-Hand-Gesture-Controlled-Telepresence-Robot--Mosaic-Udyam-2019
Our hand gestured controlled deep learning based telepresence robot that won the first prize in Mosaic, the Computer Vision event of Udyam 2019, IIT (BHU) Varanasi.

# Gesture-Recognition-using-background-elimination

## Introduction:

The problem of human computer interaction has been everlasting since the advent of computers. Terminals, promts, GUI all do fair job satisfying this, yet there is major void left unattended that limits the efficiency and performace of human-computer based tasks. The introducton of CNNs in Machine Learning has opened up a whole new era of possiblities to address the above problem. Though existing traditional image processing techniques through kinect sensors do a commendable job, they often tend to be costly and inaccessible to various sectors. Hence, we propose the usage of a CNN for the control of various tasks using simple hand gestures which seems to be a more natural and comfortable way for humans to interact with machines.

### A Brief Overview:
This project has two parts:
### 1) using dynamic gestures for controlling a robot's movements.
![Sample1](GIFS/Sample1.gif)

### 2) using gestures for performing various activities on computer screen.
![Sample2](GIFS/sample2.gif)

The full video can be watched here:
https://drive.google.com/file/d/16Y92K3qg452Ihpr63-WFUbtPVGe2QDBe/view

### The following is a table of allowed Gestures:

![](Allowed_Gestures/A1.png)  |  ![](Allowed_Gestures/A12.png) | ![](Allowed_Gestures/A15.png)
:-------------------------:|:-------------------------:|:-------------------------:
![](Allowed_Gestures/A6.png)  |  ![](Allowed_Gestures/A3.png) | ![](Allowed_Gestures/A2.png)
![](Allowed_Gestures/A9.png)  |  ![](Allowed_Gestures/LL.png) | ![](Allowed_Gestures/LR.png)
![](Allowed_Gestures/VL.png)  |  ![](Allowed_Gestures/VR.png) | ![](Allowed_Gestures/VU.png)
![](Allowed_Gestures/call.png)  |  ![](Allowed_Gestures/crock.png) | ![](Allowed_Gestures/fist.png)
![](Allowed_Gestures/fistWH.png)  |  ![](Allowed_Gestures/four.png) | ![](Allowed_Gestures/ok.png)
![](Allowed_Gestures/one.png)  |  ![](Allowed_Gestures/oneL.png) | ![](Allowed_Gestures/oneR.png)
![](Allowed_Gestures/palm.png)  |  ![](Allowed_Gestures/pinky.png) | ![](Allowed_Gestures/three.png)
![](Allowed_Gestures/tR.png)  |  ![](Allowed_Gestures/tL.png)

## Real Life Applications:
1) Telepresence through robots:
- Cases like Hazard managemet, disaster recovery, Space navigation and exploration, etc.
- In short use cases where a human's presence/touch is needed, yet too risky or economically infeasible.
  
2) Enhancing the comunication capabilities of hearing and speech impaired:
- Clubbing the Standard Hand gestures with various vernacular languages to promote smooth interaction with the general public.

## Conclusion:
Cutting the cost overhead on sophosticated sensors and equipments has enhanced the accesibility of our project to a great extent.The relatively simple yet effective structure prove to be more robust and versatile in its applications. Thus we expect the deployment of our project in various real-life cases so as to improve and accelerate the pace of human development so as to enhance the standard of our lives and move towards a sustainable future.
